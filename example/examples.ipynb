{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import requests\n","import csv\n","import logging\n","import time\n","import openai\n","import sys\n","from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n","csv.field_size_limit(10**9)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["CONFIG = {\n","    # GitHub Configuration\n","    \"github\": {\n","        \"token\": \"github_pat\",\n","        \"repo_url\": \"add_repo_url\",\n","        \"exclude_folders\": ['list of folders to exclude']\n","    },\n","    \n","    # API Configuration\n","    \"api\": {\n","        \"base_url\": \"https://llama8b.gaia.domains/v1\",\n","        \"model_name\": \"llama\",\n","        \"api_key\": \"GAIA\"\n","    },\n","    \n","    # File paths\n","    \"paths\": {\n","        \"input_csv\": \"path_to_input_file.csv\",\n","        \"output_csv\": \"path_to_summarized_output.csv\"\n","    }\n","}\n","\n","# Create all global variables needed by functions\n","GITHUB_TOKEN = CONFIG[\"github\"][\"token\"]\n","API_BASE_URL = CONFIG[\"api\"][\"base_url\"]\n","MODEL_NAME = CONFIG[\"api\"][\"model_name\"]\n","API_KEY = CONFIG[\"api\"][\"api_key\"]\n","\n","# Parameters for GitHub scraper\n","GITHUB_PARAMS = {\n","    \"repo_url\": CONFIG[\"github\"][\"repo_url\"],\n","    \"output_path\": CONFIG[\"paths\"][\"input_csv\"],\n","    \"exclude_folders\": CONFIG[\"github\"][\"exclude_folders\"]\n","}\n","\n","# Parameters for summarizer\n","SUMMARIZER_PARAMS = {\n","    \"input_path\": CONFIG[\"paths\"][\"input_csv\"],\n","    \"output_path\": CONFIG[\"paths\"][\"output_csv\"]\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_github_contents(repo_url):\n","    parts = repo_url.rstrip('/').split('/')\n","\n","    if len(parts) < 5 or parts[2] != \"github.com\":\n","        raise ValueError(\"Invalid GitHub URL. Ensure the URL is in the format: https://github.com/user/repo/tree/branch/path\")\n","\n","    user = parts[3]\n","    repo = parts[4]\n","\n","    if \"tree\" in parts:\n","        branch = parts[6]\n","        subpath = '/'.join(parts[7:]) if len(parts) > 7 else ''\n","        api_url = f\"https://api.github.com/repos/{user}/{repo}/contents/{subpath}?ref={branch}\"\n","    else:\n","        api_url = f\"https://api.github.com/repos/{user}/{repo}/contents/\"\n","\n","    headers = {\n","        \"Authorization\": f\"Bearer {GITHUB_TOKEN}\"\n","    }\n","\n","    response = requests.get(api_url, headers=headers)\n","    response.raise_for_status()\n","    return response.json()\n","\n","def process_contents(contents, paths=[], parent_path=\"\", exclude_folders=[]):\n","    headers = {\n","        \"Authorization\": f\"Bearer {GITHUB_TOKEN}\"\n","    }\n","    for item in contents:\n","        path = parent_path + item['name']\n","\n","        if item['type'] == 'dir' and item['name'] in exclude_folders:\n","            print(f\"Skipping folder: {path}\")\n","            continue\n","\n","        print(f\"Processing: {path}\")\n","\n","        if item['type'] == 'dir':\n","            dir_response = requests.get(item['url'], headers=headers)\n","            dir_response.raise_for_status()\n","            dir_contents = dir_response.json()\n","            process_contents(dir_contents, paths, path + \"/\", exclude_folders)\n","        elif item['type'] == 'file':\n","            file_response = requests.get(item['download_url'], headers=headers)\n","            file_response.raise_for_status()\n","            file_content = file_response.text\n","            paths.append({\"Path\": path, \"Content\": file_content})\n","\n","    print(f\"Finished processing. Total files processed: {len(paths)}.\")\n","    return paths\n","\n","def transform_and_write_csv(data, output_csv):\n","    with open(output_csv, mode='w', newline='', encoding='utf-8') as outfile:\n","        writer = csv.writer(outfile)\n","        for row in data:\n","            path = row['Path']\n","            content = row['Content']\n","            extension = os.path.splitext(path)[1]\n","\n","            if extension == '.md':\n","                formatted_content = f\"The following is a markdown document located at {path}\\n------\\n{content}\\n------\"\n","            elif extension == '.rs':\n","                formatted_content = f\"```rust:{path}\\n{content}\\n```\"\n","            elif extension == '.sh':\n","                formatted_content = f\"```bash:{path}\\n{content}\\n```\"\n","            elif extension == '.py':\n","                formatted_content = f\"```python:{path}\\n{content}\\n```\"\n","            elif extension == '.js':\n","                formatted_content = f\"```javascript:{path}\\n{content}\\n```\"\n","            elif extension == '.json':\n","                formatted_content = f\"```json:{path}\\n{content}\\n```\"\n","            elif extension == '.txt':\n","                formatted_content = f\"The following is a plain text file located at {path}\\n------\\n{content}\\n------\"\n","            elif extension == '.toml':\n","                formatted_content = f\"```toml:{path}\\n{content}\\n```\"\n","            elif extension == '.jsx':\n","                formatted_content = f\"```jsx:{path}\\n{content}\\n```\"\n","            elif extension == '.css':\n","                formatted_content = f\"```css:{path}\\n{content}\\n```\"\n","            elif extension == '.java':\n","                formatted_content = f\"```java:{path}\\n{content}\\n```\"\n","            elif extension == '.hpp':\n","                formatted_content = f\"```hpp:{path}\\n{content}\\n```\"\n","            elif extension == '.c':\n","                formatted_content = f\"```c:{path}\\n{content}\\n```\"\n","            elif extension == '.yml':\n","                formatted_content = f\"```yml:{path}\\n{content}\\n```\"\n","            elif extension == '.xml':\n","                formatted_content = f\"```xml:{path}\\n{content}\\n```\"\n","            else:\n","                formatted_content = f\"The following document is located at {path}\\n------\\n{content}\\n------\"\n","            writer.writerow([formatted_content])\n","\n","def run_github_scraper(repo_url=GITHUB_PARAMS[\"repo_url\"], \n","                      output_path=GITHUB_PARAMS[\"output_path\"], \n","                      exclude_folders=GITHUB_PARAMS[\"exclude_folders\"]):\n","    try:\n","        print(f\"Starting script for repository: {repo_url}\")\n","        contents = get_github_contents(repo_url)\n","        paths = process_contents(contents, exclude_folders=exclude_folders)\n","        transform_and_write_csv(paths, output_path)\n","        print(f\"CSV file '{output_path}' generated successfully.\")\n","    except requests.exceptions.HTTPError as e:\n","        print(f\"HTTP Error occurred: {e}\")\n","    except Exception as e:\n","        print(f\"An unexpected error occurred: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class ProcessingError(Exception):\n","    \"\"\"Custom exception for processing failures after retries\"\"\"\n","    pass\n","\n","def create_retry_decorator():\n","    def after_retry(retry_state):\n","        if retry_state.attempt_number >= 2: \n","            raise ProcessingError(\"Failed to process after maximum retries\")\n","        print(f\"Retry attempt {retry_state.attempt_number} after {retry_state.outcome.exception()}\")\n","\n","    return retry(\n","        retry=retry_if_exception_type((openai.APIError, openai.APITimeoutError)),\n","        stop=stop_after_attempt(2),\n","        wait=wait_exponential(multiplier=1, min=4, max=10),\n","        before_sleep=after_retry\n","    )\n","\n","@create_retry_decorator()\n","def make_api_call(client, messages, model):\n","    return client.chat.completions.create(\n","        messages=messages,\n","        model=model,\n","        stream=False,\n","    )\n","\n","def summarize(source_text):\n","    client = openai.OpenAI(base_url=API_BASE_URL, api_key=API_KEY)\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": \"\"\"\n","            You are an AI assistant designed to review pull requests (PRs) in GitHub repositories. Your task is to:\n","\n","            1. Summarize Code-related Files:\n","            - Focus on key changes in the code, including additions, deletions, and modifications.\n","            - Capture essential details such as the purpose of the code, any new functions, classes, or methods, and the overall impact of these changes on the project.\n","            - Highlight any dependencies, error handling, or performance implications.\n","\n","            2. Summarize Markdown Files:\n","            - Extract key points from documentation, readme files, and other markdown content.\n","            - Identify sections related to project setup, usage instructions, change logs, or contributor guidelines.\n","            - Note updates in the documentation and the implications for users or developers.\n","            \"\"\",\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": source_text,\n","        }\n","    ]\n","    chat_completion = make_api_call(client, messages, MODEL_NAME)\n","    return chat_completion.choices[0].message.content\n","\n","def qgen(source_text):\n","    client = openai.OpenAI(base_url=API_BASE_URL, api_key=API_KEY)\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": \"Respond with a list of 10 questions. The text in the user message must contain specific answers to each question. Each question must be on its own line. Just list the questions without any introductory text or numbers.\",\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": source_text,\n","        }\n","    ]\n","    chat_completion = make_api_call(client, messages, MODEL_NAME)\n","    return chat_completion.choices[0].message.content\n","\n","def agen(source_text, question):\n","    client = openai.OpenAI(base_url=API_BASE_URL, api_key=API_KEY)\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": \"Give a comprehensive and well-reasoned answer to the user question strictly based on the context below and try to give a detailed explanation while answering the questions. Also try to add some bonus tip to in each answer and some relevant example outside of the content.\\n\" + source_text\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": question,\n","        }\n","    ]\n","    chat_completion = make_api_call(client, messages, MODEL_NAME)\n","    return chat_completion.choices[0].message.content\n","\n","def process_row(row, csv_writer, processed_contents, row_count):\n","    try:\n","        main_content = row[0]\n","\n","        if main_content in processed_contents:\n","            print(f\"Skipping row because content has already been processed\")\n","            return row_count, 0\n","\n","        if len(main_content) > 32000:\n","            print(f\"Skipping row {row_count + 1}: content exceeds 32000 characters\")\n","            return row_count, 0\n","\n","        summary = summarize(main_content)\n","        qs = qgen(main_content)\n","        qna_list = []\n","        \n","        for q in qs.splitlines():\n","            if len(q.strip()) == 0:\n","                continue\n","            answer = agen(main_content, q)\n","            qna_list.append(f\"Q: {q}\\nA: {answer}\")\n","\n","        csv_writer.writerow([main_content, f\"Summary:\\n{summary}\"])\n","        for qna in qna_list:\n","            csv_writer.writerow([main_content, qna])\n","        \n","        processed_contents.add(main_content)\n","        row_count += 1\n","        print(f\"Processed row {row_count}\")\n","        return row_count, 0\n","\n","    except ProcessingError as pe:\n","        print(f\"Skipping row {row_count + 1} due to timeout: {str(pe)}\")\n","        return row_count, 1\n","    except Exception as e:\n","        print(f\"Error processing row {row_count + 1}: {str(e)}\")\n","        return row_count, 1\n","\n","def load_processed_contents(output_path):\n","    processed = set()\n","    if os.path.exists(output_path):\n","        with open(output_path, 'r', newline='', encoding='utf-8') as outfile:\n","            csv_reader = csv.reader(outfile)\n","            for row in csv_reader:\n","                processed.add(row[0])\n","    return processed\n","\n","def run_summarizer(input_path=SUMMARIZER_PARAMS[\"input_path\"], \n","                  output_path=SUMMARIZER_PARAMS[\"output_path\"]):\n","    processed_contents = load_processed_contents(output_path)\n","    row_count = 0\n","    skipped_rows = 0\n","\n","    try:\n","        with open(input_path, 'r', newline='', encoding='utf-8') as infile, \\\n","             open(output_path, 'a', newline='', encoding='utf-8') as outfile:\n","            \n","            csv_reader = csv.reader(infile)\n","            csv_writer = csv.writer(outfile)\n","\n","            for row in csv_reader:\n","                row_count, skipped = process_row(row, csv_writer, processed_contents, row_count)\n","                skipped_rows += skipped\n","                outfile.flush()\n","\n","    except KeyboardInterrupt:\n","        print(\"Process interrupted by user. Progress saved.\")\n","    except Exception as e:\n","        logging.error(f\"Unexpected error: {str(e)}\")\n","    finally:\n","        print(f\"Modified data has been written to {output_path}\")\n","        print(f\"Total rows summarized: {row_count}\")\n","        print(f\"Total rows skipped: {skipped_rows}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Run GitHub scraper\n","run_github_scraper()\n","# Run summarizer\n","run_summarizer()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
